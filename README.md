# Classic Book ETL Pipeline â€” *The Imitation of Christ*

> A structured, bilingual data pipeline for spiritual and linguistic insight.

![Status](https://img.shields.io/badge/status-in_progress-yellow)

##  Problem Statement

Most classic spiritual texts are available in multiple languages, but rarely are they presented in a format that allows **structured, bidirectional comparison** between the original and its translation. Scholars, students, and spiritually curious readers alike often want to ask:
- â€œWhat is the Latin original of this English phrase?â€
- â€œHow are certain key spiritual terms rendered across the text?â€
- â€œIs the paragraph structure preserved across languages?â€

But without a structured dataset, these questions are hard to answer â€” especially at scale.

##  Vision and Goals

This project aims to create a **clean, bilingual, paragraph-aligned dataset** of *The Imitation of Christ* in Latin and English â€” stored in a SQL database and fully queryable â€” to support:

- **Semantic lookup**: Find the Latin equivalent of an English passage, and vice versa
- **Translation analysis**: Explore how Latin words and themes are rendered in context
- **Concept tracking**: Follow the use of key spiritual terms like *humilitas*, *gratia*, or *imitatio*
- **Structural exploration**: Analyze the organization of the book â€” books, chapters, paragraphs, and frequency
- **Study tools**: Enable the creation of flashcards, translation exercises, and personal study aids

##  Project Scope and ETL Design

This is a handcrafted ETL (Extractâ€“Transformâ€“Load) pipeline, written in Python and SQL. It demonstrates data engineering principles applied to a real-world, text-centric domain.

### **1. Extract**

- Scraped the Latin text from *The Latin Library*
- Scraped the English text from *Christian Classics Ethereal Library*
- Stored raw texts in plain `.txt` files, preserving natural paragraph breaks

### **2. Transform**

- Aligned each book manually by paragraph (over 600 matches)
- Ensured semantic and structural coherence across languages
- Saved bilingual TSV files per book
- Cleaned aligned data to remove inconsistencies, normalize formatting.
- Split in two TSV files and prepare for loading.

### **3. Load**

- Designed PostgreSQL schema
- Loaded cleaned bilingual TSVs into PostgreSQL using SQL scripts
- Ready for complex queries, joins, NLP tasks, or downstream tools (e.g., flashcard generators)

## ðŸ“Š Example Use Cases

Once the data is loaded, it becomes a powerful tool for:

- Searching for Latin equivalents of English passages
- Analyzing how a spiritual concept (e.g., â€œgraceâ€) is expressed across the text
- Creating datasets for Latin language learners or theology students
- Exploring paragraph frequency, length, and structure across books
- Generating dynamic flashcards and quizzes from the text

## ðŸ§± Tech Stack

- **Languages**: Python, SQL
- **Tools**: VS Code, Git, GitHub, pgAdmin, PostgreSQL
- **Practices**: Modular design, idempotent scripts, error logging, CLI-ready scripts

## ðŸ“ File Structure

```
classicbook-etl-pipeline/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ aligned/
â”‚   â”‚   â”œâ”€â”€ book1_aligned.tsv
â”‚   â”‚   â”œâ”€â”€ book2_aligned.tsv
â”‚   â”‚   â”œâ”€â”€ book3_aligned.tsv
â”‚   â”‚   â””â”€â”€ book4_aligned.tsv
â”‚   â”œâ”€â”€ cleaned/
â”‚   â”‚   â”œâ”€â”€ archive/
â”‚   â”‚   â”œâ”€â”€ imitation_cleaned.tsv
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ english_kempis.txt
â”‚   â”‚   â”œâ”€â”€ latin_kempis.txt
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ split/
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ latin_alignment_template.csv
â”œâ”€â”€ docs/
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ archive/
â”‚   â”‚   â”œâ”€â”€ clean_bookI.py
â”‚   â”‚   â”œâ”€â”€ clean_bookII.py
â”‚   â”‚   â”œâ”€â”€ clean_bookIII.py
â”‚   â”‚   â”œâ”€â”€ clean_bookIV.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ extract/
â”‚   â”‚   â”œâ”€â”€ extract_english.py
â”‚   â”‚   â”œâ”€â”€ extract_latin.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ transform/
â”‚   â”‚   â”œâ”€â”€ clean_imitation.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ tools/
â”œâ”€â”€ venv/
â””â”€â”€ README.md
```


## ðŸ§ª Engineering Principles

- **Idempotency**: Scripts can run multiple times without duplicating or corrupting data
- **Error Handling**: Exceptions are caught and logged to improve robustness
- **Modularity**: Separate scripts for each ETL stage improve clarity and maintainability
- **CLI Execution**: `python run_pipeline.py` runs the pipeline end-to-end

## âœï¸ Reflections

> â€œScientia est ordinatio rerum in ratione.â€  
> *Knowledge is the ordering of things according to reason.*

This project was more than an academic or technical exercise â€” it was a spiritual and intellectual labor. Manual alignment was slow, but meaningful. It mirrors the discipline of a data engineer: **trust in structure, reverence for clarity, and devotion to detail**.

## ðŸ”® Future Work

- Automate bilingual alignment using rule-based heuristics
- Migrate the PostgreSQL database to a cloud instance (e.g., AWS RDS)
- Integrate Airflow or dbt for orchestration
- Extend the pipeline to other classical works (e.g., Saint Augustine)

## ðŸ‘¤ Author

**Juan D. Bravo**  
Aspiring Data Engineer with a background in classical languages and philosophy.  
Bridging ancient texts with modern data pipelines.
