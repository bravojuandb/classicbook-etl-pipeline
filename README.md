# Classic Book ETL Pipeline â€“ *The Imitation of Christ*

This project is a hands-on ETL (Extract, Transform, Load) pipeline built around a classic text: *The Imitation of Christ* by Thomas Ã  Kempis.

It demonstrates how to:

- **Extract** both the Latin and English versions from online sources  
- **Transform** the texts into a clean, structured bilingual dataset  
- **Load** the data into a PostgreSQL database for further querying and analysis

The entire pipeline is written in Python, following good data engineering practices:
- Organized folder structure
- Progressive script development
- Clear Git commits and daily logs
- GitHub-hosted, self-contained, and reproducible

Designed as a foundational project to learn core data engineering workflows using meaningful content.
---

## Project Structure

- `classicbook_etl_pipeline/`
  - `extract/`
    - `extract_latin.py`
    - `extract_english.py`
    - `combine_texts.py`
  - `raw_data/`
    - `latin_kempis.txt`
    - `english_kempis.txt`
  - `processed_data/`
    - `kempis_bilingual.tsv`
  - `sql/`
    - `create_tables.sql`
  - `logs/`
    - `2025-04-05.md`
  - `requirements.txt`
  - `README.md`

---

## ðŸ” Phase 1 â€” Extract

### ðŸ§ª Latin Text

> Source: [The Latin Library](https://www.thelatinlibrary.com/kempis.html)

- Fetched index page  
- Found 4 book links (Liber Iâ€“IV)  
- Extracted and cleaned Latin paragraphs  
- Saved to `raw_data/latin_kempis.txt`  

ðŸ“„ Script: `extract_latin.py`  
ðŸ“¦ Output: `latin_kempis.txt`

---

### English Text *(coming up)*

> Source: [Project Gutemberg](https://www.gutenberg.org/cache/epub/1653/pg1653-images.html)

- Write a script to extract English version of the text  
- Make it more portable and sharable using os.getenv()
- Clean and format content  
- Save to `raw_data/english_kempis.txt`  

ðŸ“„ Script: `extract_english.py`  
ðŸ“¦ Output: `english_kempis.txt`

---

## ðŸ”„ Phase 2 â€” Transform (Coming Soon)

- [ ] Align Latin and English paragraphs
- [ ] Save aligned text as `kempis_bilingual.tsv`

ðŸ“„ Script: `combine_texts.py`  
ðŸ“¦ Output: `processed_data/kempis_bilingual.tsv`

---

## Phase 3 â€” Load (Coming Soon)

- [ ] Design SQL schema for bilingual text
- [ ] Write `create_tables.sql`
- [ ] Load `.tsv` into PostgreSQL via `psql` or Python

---

## Tools Used

- `requests` â€” HTTP requests
- `BeautifulSoup` â€” HTML parsing
- `os` â€” file handling
- `utf-8` encoding â€” preserve Latin characters
- PostgreSQL â€” relational database

---

## Requirements

To install dependencies:

```bash
pip install -r requirements.txt